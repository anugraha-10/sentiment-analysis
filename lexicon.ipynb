{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lexicon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga8EIxotVFyt",
        "outputId": "087380c5-971e-4f6f-bf33-bb8d9f70c5bb"
      },
      "source": [
        "!pip install textblob\n",
        "!pip install textsearch\n",
        "!pip install contractions\n",
        "!pip install afinn\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "Collecting textsearch\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 38.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85439 sha256=4873a4f54ab8fac9eb4b3ed86788c1691a5ce284c1d2b2b8b01517576bb0a280\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch\n",
            "Successfully installed anyascii-0.3.0 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.0.58-py2.py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.58\n",
            "Collecting afinn\n",
            "  Downloading afinn-0.1.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53448 sha256=95e29f2812fdbb932cce41d30a4e9bbb2ee82e39ec9462851f9e5c67929d61d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/16/3a/9f0953027434eab5dadf3f33ab3298fa95afa8292fcf7aba75\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jStFzhu5VLlV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import textblob\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dF-dWaSVObe"
      },
      "source": [
        "dataset = pd.read_csv(r'https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2')\n",
        "\n",
        "reviews = np.array(dataset['review'])\n",
        "sentiments = np.array(dataset['sentiment'])\n",
        "\n",
        "# extract data for model evaluation\n",
        "test_reviews = reviews[35000:]\n",
        "test_sentiments = sentiments[35000:]\n",
        "sample_review_ids = [7626, 3533, 13010]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1oB1dRqVwy_",
        "outputId": "6a034feb-573f-4b13-d1a3-3c0e2e776986"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', textblob.TextBlob(review).sentiment.polarity)\n",
        "    print('-'*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REVIEW: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!\n",
            "Actual Sentiment: negative\n",
            "Predicted Sentiment polarity: -0.3625\n",
            "------------------------------------------------------------\n",
            "REVIEW: I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.\n",
            "Actual Sentiment: positive\n",
            "Predicted Sentiment polarity: 0.16666666666666674\n",
            "------------------------------------------------------------\n",
            "REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbeliaveble but you have to see it really!!!! P.s watch the carrot\n",
            "Actual Sentiment: positive\n",
            "Predicted Sentiment polarity: -0.037239583333333326\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SapP2YYV347"
      },
      "source": [
        "sentiment_polarity = \n",
        "[textblob.TextBlob(review).sentiment.polarity \n",
        "for review in test_reviews]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14VlrGXsV7z3"
      },
      "source": [
        "predicted_sentiments = ['positive' \n",
        "if score >= 0.1 else 'negative' \n",
        "for score in sentiment_polarity]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "g9n6abAAV-sq",
        "outputId": "e129d9eb-32fa-4b15-e91c-b174fb445dc2"
      },
      "source": [
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, predicted_sentiments))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, predicted_sentiments), index=labels, columns=labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.76      0.76      7490\n",
            "    positive       0.76      0.78      0.77      7510\n",
            "\n",
            "    accuracy                           0.77     15000\n",
            "   macro avg       0.77      0.77      0.77     15000\n",
            "weighted avg       0.77      0.77      0.77     15000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>5668</td>\n",
              "      <td>1822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>1675</td>\n",
              "      <td>5835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative      5668      1822\n",
              "positive      1675      5835"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF3XplPOX_FB"
      },
      "source": [
        "from afinn import Afinn\n",
        "\n",
        "afn = Afinn(emoticons=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vktX2bw9YCgj",
        "outputId": "a6bc4565-5fa3-472f-af18-34aea5f0e32d"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', afn.score(review))\n",
        "    print('-'*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REVIEW: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!\n",
            "Actual Sentiment: negative\n",
            "Predicted Sentiment polarity: -7.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.\n",
            "Actual Sentiment: positive\n",
            "Predicted Sentiment polarity: 3.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbeliaveble but you have to see it really!!!! P.s watch the carrot\n",
            "Actual Sentiment: positive\n",
            "Predicted Sentiment polarity: -3.0\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRlz2GV6YHla"
      },
      "source": [
        "sentiment_polarity = [afn.score(review) \n",
        "for review in test_reviews]\n",
        "predicted_sentiments = ['positive' \n",
        "if score >= 1.0 else 'negative' \n",
        "for score in sentiment_polarity]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "yEnwpFXCYLDO",
        "outputId": "05805b40-4b0b-49b0-f10f-6fefc91e2e94"
      },
      "source": [
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, predicted_sentiments))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, predicted_sentiments), index=labels, columns=labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.57      0.67      7490\n",
            "    positive       0.67      0.85      0.75      7510\n",
            "\n",
            "    accuracy                           0.71     15000\n",
            "   macro avg       0.73      0.71      0.71     15000\n",
            "weighted avg       0.73      0.71      0.71     15000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>4301</td>\n",
              "      <td>3189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>1134</td>\n",
              "      <td>6376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative      4301      3189\n",
              "positive      1134      6376"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}